---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Model validation

In this section, model validation is performed in order to assess the predictive performance of the selected model. This validation is conducted via k-fold cross-validation. The data set is divided into k equally sized groups [@hijmans_2012], using a percentage of randomly selected observations to run the model and the remaining for validation, iteratively for each fold. 

First we load the list of required libraries.
```{r, eval=T,message=FALSE,warning=FALSE}
requiredPackages <- c(
  #GENERAL USE LIBRARIES --------#
  "here", # Library for reproducible workflow
  "rstudioapi",  # Library for reproducible workflow
  "stringr",
  "RColorBrewer",  
  "ggplot2",
  "dplyr",
  "tidyverse",
  "R.utils",
  "ggpubr",
  "hrbrthemes",
  
  #SPATIAL DATA --------#
  "rgdal",
  "fields",
  "maps" ,
  "raster",

  #MODEL FIT --------#
  "scam",
  "plotmo",
  "SDMTools",
  "pkgbuild",
  "dismo"
  )
```

We run a function to install the required packages that are not in our system and load all the required packages.
```{r, eval=T,message=FALSE,warning=FALSE}
install_load_function <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

install_load_function(requiredPackages)

```

We define some overall settings.
```{r, eval=T,message=FALSE,warning=FALSE}
# Location of script
setwd(dirname(getSourceEditorContext()$path))

# General settings for ggplot (black-white background, larger base_size)
theme_set(theme_bw(base_size = 16))
```

We load output from the selected model saved in the previous step.
```{r, eval=T,message=FALSE,warning=FALSE}
setwd(dirname(getSourceEditorContext()$path))

load(file.path ("models", "selected_model.Rdata"))
```

## Optimum threshold

We generate a data frame with the data used in the selected model and we add the predicted values.
```{r, eval=T,message=FALSE,warning=FALSE}
  #PAdata_enviroment used in the selected model
  data<-selected_model$model

  # Predict 
  scgam.pred <- predict(selected_model, newdata=data, type="response")
  
  # Add the prediction to the data object
  data$scgam.pred <- as.vector(scgam.pred)
  head(data)
``` 

The threshold for presence-absence classification for each species is obtained as the values maximizing sensitivity plus specificity [@jimenez_etal_2007]. If the result was a range (instead of a single value), we would select the mean value of the range. 
```{r, eval=T,message=FALSE,warning=FALSE}
  # Optimizing the threshold probability
  obs <- data$occurrenceStatus
  predSCGAM_P <- data$scgam.pred
  
  # threshold optimizing
  myoptim <- optim.thresh (obs,predSCGAM_P)
  myoptim
  
  # select the threshold that maximizes the sum of sensitivity and specificity 
  myThreshold <- as.numeric((myoptim[["max.sensitivity+specificity"]]))
```

Accuracy indicators, such as AUC (Area Under the Receiver Operating Characteristic—ROC—curve), sensitivity (true predicted presences) and specificity (true predicted absences) are first computed for the all observations.
```{r, eval=T,message=FALSE,warning=FALSE}
  # Accuracy values with all observations
  accuracy (obs, predSCGAM_P, threshold=myThreshold)
  
  # Create confusion matrix with all observations
  confusion.matrix(obs, predSCGAM_P, threshold=myThreshold)
```

## k-fold validation

In this case we use a 5-fold cross-validation. 
```{r, eval=T,message=FALSE,warning=FALSE}
  # Number of groups
  k <- 5 
  # Generate groups
  groups<-kfold(data, k, by=data$occurrencestatus)
```


The model is run for each of the 5 random subset (with a 20% of the observations) and indicators are then computed using the remaining 80% of the observations. Indicators are the averaged across folds. 
```{r, eval=T,message=FALSE,warning=FALSE}
  # Initialise the confusion matrix and the accuracy table: 
  myCM <- NULL 
  myACC <- NULL
  
  # get the formula of the selected model  
  formula <- summary(selected_model)[["formula"]]
  
  # get the smoothing parameters of the selected model  
  sp <- selected_model$sp

  # loop for each group k
  for (j in 1:k) {
    # Preparation of Training Sites
    p_Training <- data[groups != j,]
    
    # Model fit
    selected_model.sp.j <- scam (formula, family=binomial(link="logit"),data=p_Training, sp=c(sp))
    
    # Predict Model
    p_validacion<-data[groups == j,]
    
    selected_model.sp.j.pred <- predict(selected_model.sp.j, newdata=p_validacion, type="response")
    p_validacion$Pred <- selected_model.sp.j.pred
    
    # Confussion matrix and accuracy table for fold j
    obs <- p_validacion$occurrenceStatus
    predSCGAM <- p_validacion$Pred
    myCM <- rbind(myCM, as.numeric(confusion.matrix(obs, predSCGAM, threshold=myThreshold)))
    myACC <- rbind(myACC, accuracy(obs, predSCGAM, threshold=myThreshold))
  } 
  
  # Mean values across k-folds
  validation_summary<-cbind(Threshold=myThreshold,
                            mean_AUC=mean(myACC$AUC),
                            mean_Omision=mean(myACC$omission.rate),
                            mean_sensitivity=mean(myACC$sensitivity),
                            mean_specificity=mean(myACC$specificity),
                            mean_Prop.Corr=mean(myACC$prop.correct))

  validation_summary
```

We save the validation summary object.
```{r, eval=F}
save(validation_summary, file = here::here("models/validation_summary.RData"))
```

